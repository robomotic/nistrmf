# Generated by Django 5.2 on 2025-04-19 14:14

import django.db.models.deletion
import django.utils.timezone
import measure.models
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('map', '0001_initial'),
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='Assessment',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('assessment_type', models.CharField(choices=[('INITIAL', 'Initial Assessment'), ('PERIODIC', 'Periodic Review'), ('INCIDENT', 'Post-Incident'), ('CHANGE', 'Change-Triggered')], max_length=100)),
                ('date_performed', models.DateField(default=django.utils.timezone.now)),
                ('findings', models.TextField()),
                ('recommendations', models.TextField()),
                ('next_assessment_date', models.DateField(default=measure.models.get_next_assessment_date)),
                ('assessment_methodology', models.TextField(help_text='Detailed description of assessment methodology')),
                ('third_party_tools', models.TextField(blank=True, help_text='Third-party tools or methodologies used')),
                ('confidence_level', models.FloatField(help_text='Confidence level in assessment (0-1)')),
                ('limitations_encountered', models.TextField(blank=True, help_text='Limitations encountered during assessment')),
                ('ai_system', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='assessments', to='map.aisystem')),
                ('performed_by', models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, to=settings.AUTH_USER_MODEL)),
            ],
        ),
        migrations.CreateModel(
            name='EnvironmentalMetric',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('metric_name', models.CharField(max_length=100)),
                ('value', models.FloatField()),
                ('unit', models.CharField(max_length=50)),
                ('measured_at', models.DateTimeField(default=django.utils.timezone.now)),
                ('notes', models.TextField(blank=True)),
                ('ai_system', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='environmental_metrics', to='map.aisystem')),
            ],
        ),
        migrations.CreateModel(
            name='HumanAIEvaluation',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('configuration', models.TextField(help_text='Describe human-AI teaming/configuration.')),
                ('intervention_points', models.TextField(help_text='Describe human intervention points.')),
                ('oversight_mechanisms', models.TextField(help_text='Describe oversight mechanisms.')),
                ('evaluation_notes', models.TextField(blank=True)),
                ('evaluated_at', models.DateTimeField(default=django.utils.timezone.now)),
                ('ai_system', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='human_ai_evaluations', to='map.aisystem')),
                ('assessment', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='human_ai_evaluations', to='measure.assessment')),
                ('evaluated_by', models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, to=settings.AUTH_USER_MODEL)),
            ],
        ),
        migrations.CreateModel(
            name='Metric',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', models.CharField(max_length=200)),
                ('description', models.TextField()),
                ('unit', models.CharField(max_length=50)),
                ('measurement_frequency', models.CharField(max_length=50)),
                ('collection_method', models.TextField()),
                ('threshold_warning', models.FloatField(help_text='Warning threshold value')),
                ('threshold_critical', models.FloatField(help_text='Critical threshold value')),
                ('measurement_type', models.CharField(choices=[('QUANTITATIVE', 'Quantitative'), ('QUALITATIVE', 'Qualitative'), ('HYBRID', 'Hybrid')], max_length=50)),
                ('confidence_level', models.FloatField(blank=True, help_text='Confidence level in measurement (0-1)', null=True)),
                ('data_requirements', models.TextField(help_text='Data required for measurement')),
                ('limitations', models.TextField(help_text='Known limitations or constraints of the metric')),
                ('third_party_dependencies', models.TextField(blank=True, help_text='Third-party dependencies affecting measurement')),
                ('validation_method', models.TextField(help_text='Method used to validate measurements')),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('ai_system', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='metrics', to='map.aisystem')),
                ('created_by', models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, to=settings.AUTH_USER_MODEL)),
                ('related_risks', models.ManyToManyField(related_name='associated_metrics', to='map.riskidentification')),
            ],
        ),
        migrations.CreateModel(
            name='MetricMeasurement',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('value', models.FloatField()),
                ('timestamp', models.DateTimeField(default=django.utils.timezone.now)),
                ('status', models.CharField(choices=[('NORMAL', 'Normal'), ('WARNING', 'Warning'), ('CRITICAL', 'Critical')], max_length=50)),
                ('notes', models.TextField(blank=True)),
                ('measurement_context', models.TextField(help_text='Contextual information about the measurement')),
                ('data_sources', models.TextField(help_text='Sources of measurement data')),
                ('confidence_score', models.FloatField(help_text='Confidence score for this measurement (0-1)', null=True)),
                ('validation_status', models.CharField(choices=[('PENDING', 'Pending Validation'), ('VALIDATED', 'Validated'), ('REJECTED', 'Validation Failed'), ('UNCERTAIN', 'Validation Uncertain')], max_length=50)),
                ('validation_notes', models.TextField(blank=True)),
                ('metric', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='measurements', to='measure.metric')),
            ],
        ),
        migrations.CreateModel(
            name='TEVV',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('test_set_description', models.TextField()),
                ('validation_method', models.TextField()),
                ('verification_method', models.TextField()),
                ('evaluation_method', models.TextField()),
                ('performance_criteria', models.TextField()),
                ('tevved_at', models.DateTimeField(default=django.utils.timezone.now)),
                ('notes', models.TextField(blank=True)),
                ('ai_system', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='tevv_records', to='map.aisystem')),
                ('performed_by', models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, to=settings.AUTH_USER_MODEL)),
            ],
        ),
    ]
