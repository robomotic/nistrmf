NISTAI100-1 AIRMF1.0
Social responsibility can refer to the organization’s responsibility “for the impacts
of its decisions and activities on society and the environment through transparent
and ethical behavior” (ISO 26000:2010). Sustainability refers to the “state of the
global system, including environmental, social, and economic aspects, in which the
needs of the present are met without compromising the ability of future generations
to meet their own needs” (ISO/IEC TR 24368:2022). Responsible AI is meant to
result in technology that is also equitable and accountable. The expectation is that
organizational practices are carried out in accord with “professional responsibility,”
defined by ISO as an approach that “aims to ensure that professionals who design,
develop, or deploy AI systems and applications or AI-based products or systems,
recognize their unique position to exert influence on people, society, and the future
ofAI”(ISO/IEC TR 24368:2022).
As directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283),
the goal of the AI RMF is to offer a resource to the organizations designing, developing,
deploying,orusingAIsystemstohelpmanagethemanyrisksofAIandpromotetrustwor-
thy and responsible development and use of AI systems. The Framework is intended to be
voluntary,rights-preserving,non-sector-specific,anduse-caseagnostic,providingflexibil-
ity to organizations of all sizes and in all sectors and throughout society to implement the
approachesintheFramework.
The Framework is designed to equip organizations and individuals – referred to here as
AI actors – with approaches that increase the trustworthiness of AI systems, and to help
foster the responsible design, development, deployment, and use of AI systems over time.
AI actors are defined by the Organisation for Economic Co-operation and Development
(OECD) as “those who play an active role in the AI system lifecycle, including organiza-
tions and individuals that deploy or operate AI” [OECD (2019) Artificial Intelligence in
Society—OECDiLibrary](SeeAppendixA).
The AI RMF is intended to be practical, to adapt to the AI landscape as AI technologies
continue to develop, and to be operationalized by organizations in varying degrees and
capacities so society can benefit from AI while also being protected from its potential
harms.
The Framework and supporting resources will be updated, expanded, and improved based
on evolving technology, the standards landscape around the world, and AI community ex-
perienceandfeedback. NISTwillcontinuetoaligntheAIRMFandrelatedguidancewith
applicable international standards, guidelines, and practices. As the AI RMF is put into
use,additionallessonswillbelearnedtoinformfutureupdatesandadditionalresources.
The Framework is divided into two parts. Part 1 discusses how organizations can frame
therisksrelatedtoAIanddescribestheintendedaudience. Next,AIrisksandtrustworthi-
ness are analyzed, outlining the characteristics of trustworthy AI systems, which include
Page2