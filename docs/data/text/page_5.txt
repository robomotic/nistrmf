NISTAI100-1 AIRMF1.0
List of Figures
Fig.1 ExamplesofpotentialharmsrelatedtoAIsystems. TrustworthyAIsystems
and their responsible use can mitigate negative risks and contribute to bene-
fitsforpeople,organizations,andecosystems. 5
Fig.2 Lifecycle and Key Dimensions of an AI System. Modified from OECD
(2022) OECD Framework for the Classification of AI systems — OECD
Digital Economy Papers. The two inner circles show AI systems’ key di-
mensions and the outer circle shows AI lifecycle stages. Ideally, risk man-
agement efforts start with the Plan and Design function in the application
context and are performed throughout the AI system lifecycle. See Figure 3
forrepresentativeAIactors. 10
Fig.3 AI actors across AI lifecycle stages. See Appendix A for detailed descrip-
tions of AI actor tasks, including details about testing, evaluation, verifica-
tion, and validation tasks. Note that AI actors in the AI Model dimension
(Figure2)areseparatedasabestpractice,withthosebuildingandusingthe
modelsseparatedfromthoseverifyingandvalidatingthemodels. 11
Fig.4 Characteristics of trustworthy AI systems. Valid & Reliable is a necessary
condition of trustworthiness and is shown as the base for other trustworthi-
ness characteristics. Accountable & Transparent is shown as a vertical box
becauseitrelatestoallothercharacteristics. 12
Fig.5 Functions organize AI risk management activities at their highest level to
govern, map, measure, and manage AI risks. Governance is designed to be
a cross-cutting function to inform and be infused throughout the other three
functions. 20
Pageii