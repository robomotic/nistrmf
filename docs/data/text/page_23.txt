NISTAI100-1 AIRMF1.0
Biasisbroaderthandemographicbalanceanddatarepresentativeness. NISThasidentified
three major categories of AI bias to be considered and managed: systemic, computational
and statistical, and human-cognitive. Each of these can occur in the absence of prejudice,
partiality, or discriminatory intent. Systemic bias can be present in AI datasets, the orga-
nizational norms, practices, and processes across the AI lifecycle, and the broader society
that uses AI systems. Computational and statistical biases can be present in AI datasets
andalgorithmicprocesses,andoftenstemfromsystematicerrorsduetonon-representative
samples. Human-cognitive biases relate to how an individual or group perceives AI sys-
tem information to make a decision or fill in missing information, or how humans think
about purposes and functions of an AI system. Human-cognitive biases are omnipresent
indecision-makingprocessesacrosstheAIlifecycleandsystemuse,includingthedesign,
implementation,operation,andmaintenanceofAI.
Bias exists in many forms and can become ingrained in the automated systems that help
make decisions about our lives. While bias is not always a negative phenomenon, AI sys-
tems can potentially increase the speed and scale of biases and perpetuate and amplify
harmstoindividuals,groups,communities,organizations,andsociety. Biasistightlyasso-
ciated with the concepts of transparency as well as fairness in society. (For more informa-
tionaboutbias,includingthethreecategories,seeNISTSpecialPublication1270,Towards
aStandardforIdentifyingandManagingBiasinArtificialIntelligence.)
Page18